{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTydcRignnY7hXM2rCxkQ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samvillasmith/EDA/blob/main/Handling_Missing_Values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Handling missing data is a crucial step in the data analysis and preprocessing workflow. Missing values can introduce bias, distort analytical results, or lead to inaccurate predictive modeling outcomes. Therefore, it's essential to manage these gaps effectively to maintain the quality and integrity of the dataset. This notebook explores several practical methods for handling missing data, including column or row removal and various imputation techniques, such as statistical imputation (mean, median, mode) and sequential imputation methods (forward-fill and backward-fill). Each technique is discussed with an emphasis on understanding their advantages, limitations, and suitable use cases, enabling you to select the most appropriate method based on your data context."
      ],
      "metadata": {
        "id": "DL7oO_SMl0Ap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wJojFHmiT2g8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Churn_Modelling_missing.csv')"
      ],
      "metadata": {
        "id": "HhMdIs19UABR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "4E-Ht60sY3AG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113856ba-4fd5-44bb-c9ae-8385d4c0e141"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              9850 non-null   float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Both Age and Gender are missing 150 values each"
      ],
      "metadata": {
        "id": "wR-1SzqqluEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVs99ljpkEQD",
        "outputId": "d5553774-efbe-440a-d823-6f7e93f63148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RowNumber            0\n",
            "CustomerId           0\n",
            "Surname              0\n",
            "CreditScore          0\n",
            "Geography            0\n",
            "Gender             150\n",
            "Age                150\n",
            "Tenure               0\n",
            "Balance              0\n",
            "NumOfProducts        0\n",
            "HasCrCard            0\n",
            "IsActiveMember       0\n",
            "EstimatedSalary      0\n",
            "Exited               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = df.dropna(axis=1)"
      ],
      "metadata": {
        "id": "2Lj0jU6ql99p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In reality, dropping these columns is a bad practice if there aren't that many missing values"
      ],
      "metadata": {
        "id": "7HlEeUdlA9fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDfAMvUNAmv-",
        "outputId": "4e723afb-169f-4893-fa92-b4af61fdbbbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 12 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Tenure           10000 non-null  int64  \n",
            " 6   Balance          10000 non-null  float64\n",
            " 7   NumOfProducts    10000 non-null  int64  \n",
            " 8   HasCrCard        10000 non-null  int64  \n",
            " 9   IsActiveMember   10000 non-null  int64  \n",
            " 10  EstimatedSalary  10000 non-null  float64\n",
            " 11  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(2)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An alternative could include dropping the rows"
      ],
      "metadata": {
        "id": "uOewrkTZBMHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = df.dropna(axis=0)"
      ],
      "metadata": {
        "id": "C7mFuIJRBI18"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVv_X3xxBPn0",
        "outputId": "8a5ce98c-ecd1-4020-ecf4-a866284b7c09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 9703 entries, 1 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        9703 non-null   int64  \n",
            " 1   CustomerId       9703 non-null   int64  \n",
            " 2   Surname          9703 non-null   object \n",
            " 3   CreditScore      9703 non-null   int64  \n",
            " 4   Geography        9703 non-null   object \n",
            " 5   Gender           9703 non-null   object \n",
            " 6   Age              9703 non-null   float64\n",
            " 7   Tenure           9703 non-null   int64  \n",
            " 8   Balance          9703 non-null   float64\n",
            " 9   NumOfProducts    9703 non-null   int64  \n",
            " 10  HasCrCard        9703 non-null   int64  \n",
            " 11  IsActiveMember   9703 non-null   int64  \n",
            " 12  EstimatedSalary  9703 non-null   float64\n",
            " 13  Exited           9703 non-null   int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputation also remains a viable option. This can be done with the mean/median if numerical, mode if categorical\n",
        "\n",
        "### Mean Imputation\n",
        "Mean imputation is one of the simplest statistical methods for handling missing numerical data. It involves replacing missing values in a numerical column with the mean (average) of the observed non-missing values in that column.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Easy and fast to compute.\n",
        "\n",
        "Maintains the original mean of the dataset.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Reduces variability in the dataset, as imputed values cluster around the mean.\n",
        "\n",
        "Potentially biases relationships between variables, since multiple identical imputed values can artificially inflate correlations.\n",
        "\n",
        "When to use mean imputation:\n",
        "\n",
        "Ideal when the proportion of missing data is small and the missing values are randomly distributed (missing completely at random).\n",
        "\n",
        "Best suited for numerical columns with relatively symmetrical distributions; if skewness or outliers are present, median imputation could be a better alternative.\n",
        "\n",
        "To effectively use mean imputation, always assess your data distribution first and evaluate the methodâ€™s suitability for your specific analytical needs."
      ],
      "metadata": {
        "id": "-Q0Dk3e1Bkn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usIRUI1HCYWk",
        "outputId": "e531d4fa-036a-47e3-f963-6296b1dfaf09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              9850 non-null   float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fillna fills the null records\n",
        "updated_df = df\n",
        "updated_df['Age'] = updated_df['Age'].fillna(df['Age'].mean())"
      ],
      "metadata": {
        "id": "F_dJc0NIBRqk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGsi5t99B_sc",
        "outputId": "f658ef2d-64ad-4e07-934a-f20ef6915a8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              10000 non-null  float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note on Median vs. Mean Imputation\n",
        "While mean imputation uses the average of numerical values, median imputation employs the middle value of the ordered dataset. Median imputation is often preferred when the data has significant skewness or contains outliers, as it is less influenced by extreme values compared to the mean. Always consider the data's distribution characteristics when choosing between mean and median imputation."
      ],
      "metadata": {
        "id": "9XMMIBZ1KoNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mode Imputation for Categorical Variables\n",
        "Mode imputation replaces missing values in categorical columns with the most frequently occurring category (the mode). It is a straightforward and effective method for handling missing categorical data.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Simple and intuitive approach.\n",
        "\n",
        "Does not require numerical operations, making it ideal for categorical data.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Can artificially inflate the frequency of the most common category.\n",
        "\n",
        "May introduce bias, especially if the proportion of missing data is high.\n",
        "\n",
        "When to use mode imputation:\n",
        "\n",
        "Suitable for categorical variables where the missing values constitute a relatively small proportion of the dataset.\n",
        "\n",
        "Ideal when no clear relationship or pattern for missingness exists.\n",
        "\n",
        "Always verify that mode imputation aligns well with your analysis objectives and that it will not significantly bias your results or interpretations."
      ],
      "metadata": {
        "id": "BjglZYdnKJUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = df\n",
        "updated_df['Gender'] = updated_df['Gender'].fillna(df['Gender'].mode()[0])"
      ],
      "metadata": {
        "id": "1wFNOGyzKZBZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj0vBUikKboC",
        "outputId": "ae9c775d-74d9-4e85-a878-9834c056fada"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward and forward filling imputation\n",
        "\n",
        "Backward fill (bfill) and forward fill (ffill) are methods for imputing missing values in a DataFrame.\n",
        "\n",
        "Backward fill (bfill): This method fills the missing value with the next valid value in the same column. In your notebook, after applying bfill to the 'Age' column in cell tqOtyv19HxEq, the missing 'Age' values were filled with the value from the next row in that column.\n",
        "Forward fill (ffill): This method fills the missing value with the previous valid value in the same column. In your notebook, after applying ffill to the 'Age' column in cell xyFee9mkIF-S, the missing 'Age' values were filled with the value from the previous row in that column.\n",
        "These methods are useful when there's a sequential relationship in the data, like time series data, where the next or previous value might be a reasonable estimate for a missing value."
      ],
      "metadata": {
        "id": "AWtHzIK9HfyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Churn_Modelling_missing.csv')"
      ],
      "metadata": {
        "id": "EPREqZHHCHBs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKnzZrB2HkqC",
        "outputId": "bb6dd0ac-4ff1-48c0-d565-2d2e29234904"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              9850 non-null   float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df"
      ],
      "metadata": {
        "id": "Q8pRVe_xHlPD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Age'] = df1['Age'].bfill()"
      ],
      "metadata": {
        "id": "tqOtyv19HxEq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR2XOVb8H8Gh",
        "outputId": "f08dcb99-24f9-418d-ca5d-709d1eebc78f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              10000 non-null  float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df"
      ],
      "metadata": {
        "id": "0qyVgmOPH_nC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Age'] = df2['Age'].ffill()"
      ],
      "metadata": {
        "id": "xyFee9mkIF-S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sndzgOPgIG-K",
        "outputId": "3da9b207-4b18-40a4-f720-6232798d06b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           9850 non-null   object \n",
            " 6   Age              10000 non-null  float64\n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we explored several practical strategies for handling missing values, including dropping columns or rows and various imputation techniques. While dropping columns or rows may simplify datasets, these approaches can lead to loss of valuable data and are typically not recommended unless missing values are extensive. Alternatively, we examined imputation methods such as mean, median, or mode substitution, which preserve the overall integrity of the data distribution. Additionally, we explored sequential imputation techniques like forward-fill (ffill) and backward-fill (bfill), especially beneficial in datasets where data points exhibit temporal or sequential dependencies.\n",
        "\n",
        "Selecting the appropriate method depends heavily on the context and nature of your dataset. It's essential to consider the potential impact of each method on downstream analyses or modeling. Therefore, thorough understanding and careful experimentation with these approaches are critical steps in preparing data effectively for accurate and reliable analysis."
      ],
      "metadata": {
        "id": "IvUkiW-OJHbK"
      }
    }
  ]
}